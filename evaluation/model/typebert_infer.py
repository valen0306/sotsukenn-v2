#!/usr/bin/env python3
"""
TypeBERT inference adapter (Phase3 DTS_MODEL).

This script is intentionally an adapter layer:
- It defines a stable JSON I/O contract for the evaluation runner.
- You can swap the backend implementation later (actual TypeBERT weights/checkpoint).

Current default backend is a safe placeholder that emits "any-typed" declarations
based on requested modules/imported names. This lets you validate the end-to-end
pipeline (extract -> infer -> inject -> tsc -> aggregate) before the real model is wired.

Input (stdin JSON):
{
  "repo": {"url": "...", "slug": "..."},
  "modules": {
    "pkg": {
      "defaultImport": true|false,
      "named": ["foo", "bar"],
      "typeNamed": ["Baz", "Qux"]
    },
    ...
  }
}

Output (stdout JSON):
{
  "ok": true,
  "backend": "stub",
  "dts": "declare module 'pkg' { ... }\\n..."
}
"""

from __future__ import annotations

import argparse
import hashlib
import json
import os
import sys
from typing import Any, Dict, List


def _esc_module(s: str) -> str:
    return s.replace("\\\\", "\\\\\\\\").replace("'", "\\\\'")


def build_any_dts(modules: Dict[str, Dict[str, Any]], *, pkg_name: str) -> str:
    chunks: List[str] = []
    chunks.append(f"// Auto-generated by {pkg_name} (TypeBERT adapter: stub backend)\\n\\n")
    for mod in sorted(modules.keys()):
        info = modules.get(mod) or {}
        default_import = bool(info.get("defaultImport"))
        named = sorted(set([x for x in (info.get("named") or []) if isinstance(x, str)]))
        type_named = sorted(set([x for x in (info.get("typeNamed") or []) if isinstance(x, str)]))
        chunks.append(f"declare module '{_esc_module(mod)}' {{\\n")
        if default_import:
            chunks.append("  const __default: any;\\n  export default __default;\\n")
        # generic anchor export (helps namespace import)
        chunks.append("  export const __any: any;\\n")
        for n in named:
            if n.isidentifier():
                chunks.append(f"  export const {n}: any;\\n")
        for t in type_named:
            if t.isidentifier():
                chunks.append(f"  export type {t} = any;\\n")
        chunks.append("}\\n\\n")
    return "".join(chunks)


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--backend", default="stub", choices=["stub"], help="Inference backend")
    ap.add_argument("--cache-dir", default="", help="Optional cache dir for model outputs")
    args = ap.parse_args()

    raw = sys.stdin.read()
    try:
        req = json.loads(raw)
    except Exception as e:
        sys.stderr.write(f"failed to parse stdin json: {e}\\n")
        return 2

    modules = req.get("modules") or {}
    if not isinstance(modules, dict):
        modules = {}

    # cache (optional)
    cache_dir = args.cache_dir.strip()
    cache_key = hashlib.sha1(raw.encode("utf-8")).hexdigest()
    if cache_dir:
        os.makedirs(cache_dir, exist_ok=True)
        cache_path = os.path.join(cache_dir, f"{cache_key}.json")
        if os.path.exists(cache_path):
            sys.stdout.write(open(cache_path, "r", encoding="utf-8").read())
            return 0

    if args.backend == "stub":
        dts = build_any_dts(modules, pkg_name="evaluation/model/typebert_infer.py")
        out = {"ok": True, "backend": "stub", "dts": dts}
    else:
        out = {"ok": False, "backend": args.backend, "error": "unsupported backend"}

    out_json = json.dumps(out, ensure_ascii=False)
    if cache_dir:
        with open(cache_path, "w", encoding="utf-8") as f:
            f.write(out_json)
    sys.stdout.write(out_json)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())


