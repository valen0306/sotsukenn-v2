## 改訂版：現状を踏まえた方針A（今後の方針）

### 0. 結論（最初に言う1文）
現状の評価ハーネス（`.d.ts`注入 → consumerで`tsc` → ログ取得）があるため方針Aは十分適用可能。  
ただし「研究としての新規性」を立てるために、**宣言単位の追跡（ID化）**と **Δerrors による弱教師データ生成**を追加し、Localizer/Rerankerを段階的に導入する。

---

### 1. 現状資産をどう位置づけるか（ゼミ用）
#### すでに揃っている前提（応用可能な理由）
- consumerに `.d.ts` を注入して `tsc` を回すパイプライン
- `tsc` の診断（エラー）を取得できるログ基盤
- 再現性確保のための実行手順（固定化の意識）

→ これらは方針Aの **学習データ生成と評価ループ**の土台。

#### 足りないもの（研究として成立させるための最小追加）
- **宣言ID**: どの `.d.ts` のどの宣言を変えたか追える
- **候補ID**: Top-k のどれを採用したか追える
- **Δerrorsログ**: 候補を変えたとき、エラーが増減したか（弱教師）

---

### 2. 提案（方針A）を“現状に合わせて”定義し直す
方針Aの中心を次の2点に固定する。

#### 新規性の焦点
- **Error Localizer**: `tsc`エラーから「直すべき宣言」を局所化して探索空間を縮める
- **Error-aware Reranker**: `tsc`の結果（Δerrors）を教師にして「次に試す候補」を学習で当てる

※ Base Generator（TypeBERT相当）は“既存利用”で良い。新規性はLocalize/Rerankに置く。

---

### 3. 実装・研究の進め方（段階的に“成果が出る”順）
Apple M4 32GBでは学習より `tsc` 回数がボトルネックになりやすい。  
よって、まず **探索回数を減らす仕組み**から入れる。

#### Phase 0：ログとIDの整備（最優先）
**目的**: 現状の資産を“学習できる資産”に変換する。
- `tsc`診断をJSON化（`code/file/range/message`）
- `.d.ts`宣言を分割して `declaration_id` を付与
- Top-k候補に `candidate_id` を付与
- 差し替え試行ごとに **Δerrors** を記録

**この時点でできること**
- 「どの宣言変更が、どのエラーを減らしたか」をログとして説明可能  
→ ここだけでもゼミで「次の研究段階へ進める根拠」が出せる

#### Phase 1：Localizer v0（ルール）で探索を減らす
**目的**: 学習なしでも“研究としての仮説”を検証する第一歩。
- エラー位置のASTから `call/property/import` を辿り、関連しそうな宣言 Top-M を返す
- その Top-M だけ探索する

**期待できる結果**
- 成立率が同程度でも、`tsc`回数（試行回数）が減る
- 悪化ステップ（エラー増）が減る可能性

**ゼミでの言い方**
- “`tsc`のエラー位置≠原因宣言”問題に対し、局所化で探索空間を縮める

#### Phase 2：ベースライン確立（比較できる状態にする）
**目的**: 提案の効果を言い切るための比較軸を作る。

最低限の比較を揃える：
- **B0**: Base Top-1固定
- **B1**: 単純探索（Localizerなし、Top-k順）
- **A1**: Localizerあり探索（学習なし）

**アウトプット**
- “局所化だけでどれだけ回数が減ったか”のグラフ
- M4環境で回る実験スケール感が確定

#### Phase 3：学習データ生成（弱教師）を本格化
**目的**: Rerankerを学習させるためのデータを自動で貯める。
- Localizerが出した宣言候補について、Top-k候補を一つずつ差し替えて `tsc`
- Δerrors をログに貯め、pairwise（AよりBが良い）形式に変換

**ポイント**
- 人手で正解型を作らない
- “`tsc`が改善したか”を教師にする＝卒論として再現性が高い

#### Phase 4：Reranker v0（軽量ML）で「収束」を改善
**目的**: 方針Aの主張（探索を学習で賢くする）を成立させる。
- まずは軽量モデル（ロジスティック / LightGBM）で十分
- 入力: エラー特徴（code等）＋宣言特徴＋候補型特徴
- 出力: Top-k順位（次に試す候補を決める）

**期待結果（言えると強い）**
- 同じ成功率で `tsc`回数をさらに削減
- 悪化率（Δ>0）を減らす
- any率を上げずに到達（目的関数を入れる場合）

#### Phase 5：統合評価（A3）と分析（卒論の核）
- **A3**: Localizer + Reranker（提案）
- エラーコード別（TS2345など）で効果差を分析
- “効く条件/効かない条件”を整理（module解決系は別枠など）

---

### 4. 研究質問（改訂版）
- **RQ1**: Localizerは探索空間を縮め、`tsc`回数を減らせるか？
- **RQ2**: RerankerはΔerrorsを教師にして、収束をより速く・安定にできるか？
- **RQ3**: 成功率を維持しつつ、any率（情報落ち）を抑制できるか？

---

### 5. M4 32GB を踏まえた実験設計（無理しない方針）
- 新規性は「大規模モデル学習」ではなく **探索効率化**に置く
- まず軽量MLで効果を出す（CPUで回る）
- `tsc`回数削減＝実験が回る＝研究が進む、という設計
- consumer数は段階拡張（10→20→30）

---

### 6. deepresearch（やるならこの順）
Phase 1/2の結果が出てから着手するのが効率的。

優先順：
1. error localization（コンパイルエラーから原因箇所を絞る研究）
2. compiler feedback learning（コンパイラ結果を学習信号にする系譜）
3. TypeScript module解決・exports不整合の分析研究（実験統制の根拠）

---

### まとめ（ゼミでの締め）
- 現状のハーネスは方針Aの土台として活用できる
- 追加するのは「宣言ID化」「Δerrorsの弱教師ログ」「Localizer→Reranker」の段階導入
- 成果は“成立率”だけでなく **探索回数/悪化率/any率**で示し、研究としての貢献を明確化する


